{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3f87f393",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello world, lets start playing with pytorch!\n"
     ]
    }
   ],
   "source": [
    "print(\"Hello world, lets start playing with pytorch!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "c10e8418",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.7.0+cu128\n",
      "12.8\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(torch.__version__)\n",
    "print(torch.version.cuda)\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "c3f34a91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Jun  3 19:37:43 2025       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 576.02                 Driver Version: 576.02         CUDA Version: 12.9     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                  Driver-Model | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA GeForce RTX 4080      WDDM  |   00000000:01:00.0  On |                  N/A |\n",
      "|  0%   54C    P3             37W /  340W |    3055MiB /  16376MiB |     40%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI              PID   Type   Process name                        GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|    0   N/A  N/A            2196      C   ...s\\Python\\Python312\\python.exe      N/A      |\n",
      "|    0   N/A  N/A            2948    C+G   ...5n1h2txyewy\\TextInputHost.exe      N/A      |\n",
      "|    0   N/A  N/A            5632    C+G   ...ntrolPanel\\SystemSettings.exe      N/A      |\n",
      "|    0   N/A  N/A            8184    C+G   ...8bbwe\\PhoneExperienceHost.exe      N/A      |\n",
      "|    0   N/A  N/A           13076    C+G   ...xyewy\\ShellExperienceHost.exe      N/A      |\n",
      "|    0   N/A  N/A           17028    C+G   ...y\\StartMenuExperienceHost.exe      N/A      |\n",
      "|    0   N/A  N/A           18216    C+G   ...se 3 Host\\Razer Synapse 3.exe      N/A      |\n",
      "|    0   N/A  N/A           23356    C+G   ...\\app-3.4.20\\GitHubDesktop.exe      N/A      |\n",
      "|    0   N/A  N/A           27100    C+G   ...lpaper_engine\\wallpaper64.exe      N/A      |\n",
      "|    0   N/A  N/A           27320    C+G   ...ps\\Microsoft VS Code\\Code.exe      N/A      |\n",
      "|    0   N/A  N/A           35772    C+G   ...ef.win7x64\\steamwebhelper.exe      N/A      |\n",
      "|    0   N/A  N/A           37012    C+G   ...s\\Mozilla Firefox\\firefox.exe      N/A      |\n",
      "|    0   N/A  N/A           37556    C+G   C:\\Windows\\explorer.exe               N/A      |\n",
      "|    0   N/A  N/A           37752    C+G   ...h_cw5n1h2txyewy\\SearchApp.exe      N/A      |\n",
      "|    0   N/A  N/A           38784    C+G   ...App_cw5n1h2txyewy\\LockApp.exe      N/A      |\n",
      "|    0   N/A  N/A           39868    C+G   ...cord\\app-1.0.9193\\Discord.exe      N/A      |\n",
      "|    0   N/A  N/A           40340    C+G   ...-x64\\jre-legacy\\bin\\javaw.exe      N/A      |\n",
      "|    0   N/A  N/A           40352    C+G   ...\\SubAgent\\AlienFXSubAgent.exe      N/A      |\n",
      "|    0   N/A  N/A           40832    C+G   ...s\\Mozilla Firefox\\firefox.exe      N/A      |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!NVIDIA-SMI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad58d879",
   "metadata": {},
   "source": [
    "### INTRODUCTION TO TENSORS\n",
    "Pytorch tensors are creaties using `torch.tensor()` : *https://docs.pytorch.org/docs/stable/generated/torch.tensor.html#torch.tensor*\n",
    "\n",
    "Tensors can be broken down into 4 categories so far:\n",
    "* **scalar(x)** is 0 dimensions, 0 square brackets; a single number; Lower(a)\n",
    "* **vector([x, x])** is 1 dimension, 1 square brackets; a number with direction. i.e wind speed & direction, may have more numbers; Lower(y)\n",
    "* **MATRIX([[x, x], [x, x]])** is 2 dimensions, 2 square brackets; 2 dimensional array of numbers; Upper(Q)\n",
    "*  **TENSOR([x, x, x], [x, x, x], [x, x, x])** is n dimensions, n square brackets; 0 dimensional tensor is scalar, 1 dimension is vector, 2 dimension is matrix; Upper(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9dee9a3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(7)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scalar\n",
    "scalar = torch.tensor(7) # torch.tensor(data, *, dtype=None, device=None, requires_grad=False, pin_memory=False) → Tensorr\n",
    "scalar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3487f4e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scalar.ndim\n",
    "\n",
    "# 0 dimensions because no brackets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "308337dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get tensor back as Python int\n",
    "scalar.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fbea12b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scalar.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0a07d449",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([7, 7])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Vector\n",
    "vector = torch.tensor([7, 7])\n",
    "vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "422f58d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector.ndim\n",
    "\n",
    "# 1 dimension bc 1 bracket pair ...([x, x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4e974c29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "96fd8742",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 7,  8],\n",
       "        [ 9, 10]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MATRIX\n",
    "\n",
    "MATRIX = torch.tensor([[7, 8], \n",
    "                       [9, 10]])\n",
    "\n",
    "MATRIX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "89a2b437",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MATRIX.ndim\n",
    "\n",
    "# 2 dimensions bc 2 bracket pairs, ...([[x, x], [x, x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "405dc21c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([7, 8])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MATRIX[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9cfe1646",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 2])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MATRIX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "70151bab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1, 2, 3, 1, 2],\n",
       "         [3, 6, 9, 2, 3],\n",
       "         [2, 4, 5, 3, 3],\n",
       "         [7, 5, 3, 4, 3]]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TENSOR\n",
    "\n",
    "TENSOR = torch.tensor([[[1, 2 , 3, 1, 2], \n",
    "                        [3, 6, 9, 2, 3], \n",
    "                        [2, 4, 5, 3, 3],\n",
    "                        [7, 5, 3, 4, 3]]])\n",
    "\n",
    "TENSOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "df703c19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TENSOR.ndim\n",
    "\n",
    "# 3 dimensions bc 3 bracket pairs, ...([[[x, x, x], [x, x, x], [x, x, x]]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0ed76e52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 4, 5])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TENSOR.shape\n",
    "\n",
    "#torch.Size([1, 4, 5])\n",
    "# [1, ... Encompases the whole tensor as 1 unit due to all bracket pairs being nested.\n",
    "#  4, ... Encompases the 4 bracket pairs (Can be any amount of bracket paits as long as more than 1)\n",
    "#  5] ... Enxompases the 5 integers in each bracket (can be any amount of integers as long as more than 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59d2afe9",
   "metadata": {},
   "source": [
    "torch.Size([1, y, z])\n",
    "\n",
    "    - [1, ... Encompases the whole tensor as 1 unit due to all bracket pairs being nested.\n",
    "    - y, ... Encompases the y bracket pairs (Can be any amount of bracket paits as long as more than 1)\n",
    "    - z] ... Enxompases the z integers in each bracket (can be any amount of integers as long as more than 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "354c56d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 3, 1, 2],\n",
       "        [3, 6, 9, 2, 3],\n",
       "        [2, 4, 5, 3, 3],\n",
       "        [7, 5, 3, 4, 3]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TENSOR[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f594e3aa",
   "metadata": {},
   "source": [
    "### RANDOM TENSORS\n",
    "\n",
    "Randomized Pytorch tensors are created via `torch.rand()`: *https://docs.pytorch.org/docs/stable/generated/torch.rand.html#torch-rand*\n",
    "\n",
    "Why random tensors?\n",
    "* Random tensors are important bc neural networks learn by starting with tensors of random numbers, then adjusting those random numbers to better represent the data.\n",
    "\n",
    "`Start with random nunbers -> look at daa -> update random numbers -> look at data -> update random numbers`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "766c858f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.7107, 0.2933, 0.2982, 0.5578],\n",
       "        [0.0533, 0.5855, 0.2348, 0.9792],\n",
       "        [0.3530, 0.3641, 0.9924, 0.5023]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a random tensor of size/shape (3, 4)\n",
    "random_TENSOR = torch.rand(3, 4)\n",
    "\n",
    "random_TENSOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9db00e91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([224, 224, 3]), 3)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a random tensor with similar shape to an image tensor\n",
    "random_image_size_TENSOR = torch.rand(size=(224, 224, 3)) # height, width, color channels (R, G, B)\n",
    "\n",
    "random_image_size_TENSOR.shape, random_image_size_TENSOR.ndim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a57c2685",
   "metadata": {},
   "source": [
    "### ZEROS & ONES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ab22ccf3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create tensor of all zeros\n",
    "zeros = torch.zeros(size=(3,4))\n",
    "zeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5153c89d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zeros*random_TENSOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3183ff85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a tensor of all ones\n",
    "ones = torch.ones(size=(3, 4))\n",
    "ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9985e83c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ones.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "aa98dd2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.7107, 0.2933, 0.2982, 0.0000],\n",
       "        [0.0533, 0.5855, 0.2348, 0.0000],\n",
       "        [0.3530, 0.3641, 0.9924, 0.0000]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_with_zero_column = random_TENSOR.clone()\n",
    "tensor_with_zero_column[:, 3] = 0\n",
    "tensor_with_zero_column\n",
    "\n",
    "# makes the last column of the random_TENSOR all zeros"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c499622",
   "metadata": {},
   "source": [
    "### CREATING A RANGE OF TENSORS & TENSORS-LIKE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d18492c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10]),\n",
       " tensor([10,  9,  8,  7,  6,  5,  4,  3,  2,  1,  0]))"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use torch.arange(start, end, step) to create a range of numbers\n",
    "one_to_ten = torch.arange(0, 11, 1)\n",
    "one_to_ten, one_to_ten.flip(0) # reverses range\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "98f4541c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating tensors-like\n",
    "ten_zeros = torch.zeros_like(one_to_ten)\n",
    "ten_zeros"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47258b6b",
   "metadata": {},
   "source": [
    "### TENSOR DATATYPES\n",
    "\n",
    "Tensor datatypes are one of the 3 big errors you'll run into with PyTorch & deep learning:\n",
    "1. Tensors not right datatype\n",
    "2. Tensors not right shape\n",
    "3. Tensors not right device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "378e773a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3.3000, 6.6000, 9.9000])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# FLoat 32 tensor\n",
    "float_32_tensor = torch.tensor([3.3, 6.6, 9.9], \n",
    "                               dtype=None, # what datatype is the tensor; defaults to float32 if not specified (e.g float32 or float16) (float16 is half precision to float32)\n",
    "                                 device=None, # what device the tensor is on; device defaults to CPU if not specified (e.g. 'cpu' or 'cuda:0' for GPU) (e.g. 'cuda:0' for first GPU or 'cuda:1' for second GPU)\n",
    "                                    requires_grad=False) # whether or not to track gradients with this tensors operations; requires_grad defaults to False if not specified\n",
    "\n",
    "float_32_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "bf2b51a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float_32_tensor.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "16284b4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3.3008, 6.6016, 9.8984], dtype=torch.float16)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float_16_tensor = float_32_tensor.type(torch.float16) # convert to float16\n",
    "float_16_tensor\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3f97af6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3.3000, 6.6000, 9.9000], dtype=torch.float64)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float_64_tensor = float_32_tensor.type(torch.float64) # convert to float64\n",
    "float_64_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c1d8459d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([10.8926, 43.5703, 97.9945])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = float_32_tensor * float_16_tensor \n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "32135b6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([10.8900, 43.5600, 98.0100])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float_32_tensor * float_32_tensor # will work because same data type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d1c49d03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([10.8900, 43.5600, 98.0100], dtype=torch.float64)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float_32_tensor * float_64_tensor # will not because same data type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e77f5334",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3, 6, 9], dtype=torch.int32)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int_32_tensor = torch.tensor([3, 6, 9], dtype=torch.int32) # create int32 tensor\n",
    "int_32_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8e3c7004",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 9.9000, 39.6000, 89.1000])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float_32_tensor * int_32_tensor # will work because int32 can be converted to float32"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d762b6ef",
   "metadata": {},
   "source": [
    "### GETTING INFORMATION FROM TENSORS (TENSOR ATTRIBUTES)\n",
    "\n",
    "1. Tensors not right datatype: To get datatype from tensor use, `tensor.dtype`\n",
    "2. Tensors not right shape: To get shape/size from a tensor use, `tensor.shape`\n",
    "3. Tensors not right device: To get device from a tensor use, `tensor.device`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c998a3cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.6655, 0.0756, 0.2046, 0.4797],\n",
       "        [0.1260, 0.1927, 0.9101, 0.4148],\n",
       "        [0.9483, 0.8523, 0.4945, 0.2175]], device='cuda:0')"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a tensor\n",
    "some_TENSOR = torch.rand(size=(3, 4), device=\"cuda:0\") # create a tensor on the first GPU (if available)\n",
    "some_TENSOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2fe76cc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.6655, 0.0756, 0.2046, 0.4797],\n",
      "        [0.1260, 0.1927, 0.9101, 0.4148],\n",
      "        [0.9483, 0.8523, 0.4945, 0.2175]], device='cuda:0')\n",
      "Datatype of tensor: torch.float32\n",
      "Shape of tensor: torch.Size([3, 4])\n",
      "Device tensor is on: cuda:0\n"
     ]
    }
   ],
   "source": [
    "# Find out the details about some_TENSOR\n",
    "print(some_TENSOR)\n",
    "print(f\"Datatype of tensor: {some_TENSOR.dtype}\")\n",
    "print(f\"Shape of tensor: {some_TENSOR.shape}\")\n",
    "print(f\"Device tensor is on: {some_TENSOR.device}\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdb505c6",
   "metadata": {},
   "source": [
    "### MANIPULATING TENSORS (TENSOR OPERATIONS)\n",
    "\n",
    "Tensor operations include:\n",
    "* Addition\n",
    "* Subtraction\n",
    "* Multiplication (*element-wise*)\n",
    "* Division\n",
    "* Matrix Multiplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "37855828",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([11, 12, 13])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a tensor & add 10 to it\n",
    "TENSOR_1 = torch.tensor([1, 2, 3])\n",
    "TENSOR_1 + 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1f5ffa68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([10, 20, 30])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Multiplay the tensor by 10\n",
    "TENSOR_1 * 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "1bbacbbf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-9, -8, -7])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Subtract 10 from the tensor\n",
    "TENSOR_1 - 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a3ccc4b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([10, 20, 30])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Try out Pytorch in-built functions\n",
    "torch.mul(TENSOR_1, 10) # multiply by 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "6e5ac21b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([11, 12, 13])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add 10 to the tensor\n",
    "torch.add(TENSOR_1, 10) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23e2c512",
   "metadata": {},
   "source": [
    "### MATRIX MULTIPLICATION\n",
    "\n",
    "*Two main ways to preform multiplication in neural networks & deep learning:*\n",
    "1. Element-Wise multiplication\n",
    "2. Matrix Multiplication (The Dot Product, e.g (a•b))\n",
    "\n",
    "There are 2 main rules to satisfy when preforming Matrix Multiplication\n",
    "1. The **inner dimensions** must match:\n",
    "* `(3,2) @ (3, 2)` won't work\n",
    "* `(2,3) @ (3, 2)` will work\n",
    "* `(3,2) @ (2, 3)` will work\n",
    "\n",
    "2. The resulting Matrix has the shape of the **outer dimensions**:\n",
    "* `(2, 3) @ (3, 2)` -> `(2, 2)`\n",
    "* `(3, 2) @ (2, 3)` -> `(3, 3)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "8a8928e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 2, 3]) * tensor([1, 2, 3])\n",
      "Equals: tensor([1, 4, 9])\n"
     ]
    }
   ],
   "source": [
    "# Element-Wise multiplication\n",
    "print(TENSOR_1, '*', TENSOR_1)\n",
    "print(f\"Equals: {TENSOR_1 * TENSOR_1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "39921599",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(14)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Matrix multiplication\n",
    "torch.matmul(TENSOR_1, TENSOR_1) # tensor([1, 2, 3]) • tensor([1, 2, 3]) dot product\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "897ff28b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Matrix multiplication by hand\n",
    "1*1 + 2*2 + 3*3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "8adc6bfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 0 ns\n",
      "tensor(14)\n"
     ]
    }
   ],
   "source": [
    "# Matrix multiplication by hand with torch\n",
    "# DONT USE THIS, USE torch.matmul() INSTEAD\n",
    "%time\n",
    "value = 0\n",
    "for i in range(len(TENSOR_1)):\n",
    "    value += TENSOR_1[i] * TENSOR_1[i]\n",
    "\n",
    "print(value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "2a8d3946",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 0 ns\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(14)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# USE THIS INSTEAD OF THE ABOVE AND BELOW\n",
    "%time\n",
    "torch.matmul(TENSOR_1, TENSOR_1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "e00a2d55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(14)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Matrix multiplication with @ operator\n",
    "TENSOR_1 @ TENSOR_1 # @ is the same as torch.matmul(), tho less readable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90557598",
   "metadata": {},
   "source": [
    "### COMMON ERROR IN DEEP LEARING: SHAPE ERROR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "8e03a6ee",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (2x3 and 2x3)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[51]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Shape Error\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmatmul\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrand\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m3\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrand\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m3\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# will throw an error because the inne dimensions don't match for matrix multiplication\u001b[39;00m\n",
      "\u001b[31mRuntimeError\u001b[39m: mat1 and mat2 shapes cannot be multiplied (2x3 and 2x3)"
     ]
    }
   ],
   "source": [
    "# Shape Error\n",
    "torch.matmul(torch.rand(2, 3), torch.rand(2, 3)) # will throw an error because the inne dimensions don't match for matrix multiplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aa4c343",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0197, 0.6159, 0.6097],\n",
       "        [0.3468, 0.4634, 0.0968],\n",
       "        [0.5049, 0.4776, 0.2267]])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Will work because the inner dimensions match (3 in this case)\n",
    "torch.matmul(torch.rand(3, 2), torch.rand(2, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e924ef1",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (3x2 and 3x2)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[94]\u001b[39m\u001b[32m, line 10\u001b[39m\n\u001b[32m      2\u001b[39m TENSOR_A = torch.tensor([[\u001b[32m1\u001b[39m, \u001b[32m2\u001b[39m],\n\u001b[32m      3\u001b[39m                         [\u001b[32m3\u001b[39m, \u001b[32m4\u001b[39m],\n\u001b[32m      4\u001b[39m                         [\u001b[32m5\u001b[39m, \u001b[32m6\u001b[39m]])\n\u001b[32m      6\u001b[39m TENSOR_B = torch.tensor([[\u001b[32m7\u001b[39m, \u001b[32m8\u001b[39m],\n\u001b[32m      7\u001b[39m                         [\u001b[32m9\u001b[39m, \u001b[32m10\u001b[39m],\n\u001b[32m      8\u001b[39m                         [\u001b[32m11\u001b[39m, \u001b[32m12\u001b[39m]])                 \n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmatmul\u001b[49m\u001b[43m(\u001b[49m\u001b[43mTENSOR_A\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mTENSOR_B\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# will throw an error because the inner dimensions don't match (2 != 3)\u001b[39;00m\n",
      "\u001b[31mRuntimeError\u001b[39m: mat1 and mat2 shapes cannot be multiplied (3x2 and 3x2)"
     ]
    }
   ],
   "source": [
    "# Shape for Matrix multiplication\n",
    "TENSOR_A = torch.tensor([[1, 2],\n",
    "                        [3, 4],\n",
    "                        [5, 6]])\n",
    "\n",
    "TENSOR_B = torch.tensor([[7, 8],\n",
    "                        [9, 10],\n",
    "                        [11, 12]])                 \n",
    "\n",
    "torch.matmul(TENSOR_A, TENSOR_B) # will throw an error because the inner dimensions don't match (2 != 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55eb766c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([3, 2]), torch.Size([3, 2]))"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TENSOR_A.shape, TENSOR_B.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c503bfe4",
   "metadata": {},
   "source": [
    "To fix a shape issue , we can manipulate the shape of a tensor using a **transpose**.\n",
    "\n",
    "A **transpose** switches the axes or dimensions of a given tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5663f8eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 7,  8],\n",
       "         [ 9, 10],\n",
       "         [11, 12]]),\n",
       " torch.Size([3, 2]))"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TENSOR_B, TENSOR_B.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5eb611a",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'TENSOR_B' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Transpose TENSOR_B to make the inner dimensions match\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[43mTENSOR_B\u001b[49m.T, TENSOR_B.T.shape\n",
      "\u001b[31mNameError\u001b[39m: name 'TENSOR_B' is not defined"
     ]
    }
   ],
   "source": [
    "# Transpose TENSOR_B to make the inner dimensions match\n",
    "TENSOR_B.T, TENSOR_B.T.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03a17755",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original shapes: TENSOR_A: torch.Size([3, 2]), TENSOR_B: torch.Size([3, 2]) \n",
      "\n",
      "Transposed shapes: TENSOR_A: torch.Size([3, 2]), TENSOR_B: torch.Size([2, 3]) \n",
      "\n",
      "Multiplying: torch.Size([3, 2]) @ torch.Size([2, 3]) <-- inner dimensions match \n",
      "\n",
      "Result: \n",
      "\n",
      "tensor([[ 23,  29,  35],\n",
      "        [ 53,  67,  81],\n",
      "        [ 83, 105, 127]])\n",
      "\n",
      " Result shape: torch.Size([3, 3]) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# The matrix multiplication operation will now work once Tensor_A or Tensor_B is transposed\n",
    "print(f\"Original shapes: TENSOR_A: {TENSOR_A.shape}, TENSOR_B: {TENSOR_B.shape} \\n\")\n",
    "print(f\"Transposed shapes: TENSOR_A: {TENSOR_A.shape}, TENSOR_B: {TENSOR_B.T.shape} \\n\")\n",
    "print(f\"Multiplying: {TENSOR_A.shape} @ {TENSOR_B.T.shape} <-- inner dimensions match \\n\")\n",
    "\n",
    "result = torch.matmul(TENSOR_A, TENSOR_B.T)\n",
    "print(f\"Result: \\n\")\n",
    "print(result)\n",
    "\n",
    "print(f\"\\n Result shape: {result.shape} \\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "047de312",
   "metadata": {},
   "source": [
    "### FINDING THE MIN, MAX, MEAN, SUM, ETC. OF A TENSOR (TENSOR AGGREGATION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fc48275",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 1, 11, 21, 31, 41, 51, 61, 71, 81, 91]), torch.int64)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a tensor\n",
    "x = torch.arange(1, 100, 10)\n",
    "x, x.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf499f9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0), tensor(0))"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find the min\n",
    "torch.min(x), x.min() # returns the minimum value in the tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb488601",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(90), tensor(90))"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find the max\n",
    "torch.max(x), x.max() # returns the maximum value in the tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "619d7b29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(45.), tensor(45.))"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find the mean\n",
    "torch.mean(x.type(torch.float32)), x.type(torch.float32).mean() # returns the mean of the tensor (must convert to float or complex number first)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0b1a21a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(450), tensor(450))"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find the sum\n",
    "torch.sum(x), x.sum() # returns the sum of the tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59565e9f",
   "metadata": {},
   "source": [
    "### FINDING THE POSITIONAL MIN & MAX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66761f1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1, 11, 21, 31, 41, 51, 61, 71, 81, 91])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af30d928",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Returns the index of the minimum value in the tensor\n",
    "x.argmin()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c61c92c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d65fa5fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(9)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Returns the index of the maximum value in the tensor\n",
    "x.argmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd5c6791",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(91)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efcea739",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Returns the minimum value in the tensor\n",
    "x[x.argmin()] "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05988563",
   "metadata": {},
   "source": [
    "### RESHAPING, STACKING, SQUEEZING, & UNSQUEEZING TENSORS\n",
    "\n",
    "* Reshaping - Reshapes an input tensor to a defined shape.\n",
    "* View - Returns a view of an input tensor of a certain shape, but keeps the shape of the tensor\n",
    "* Stacking - Combine multiple tensors on top of eachother (vstack) or side by side (hstack).\n",
    "* Squeeze - Removes all `1` dimensions from a tensor\n",
    "* Unsqueeze - add a `1` dimention to a target tensor\n",
    "* Permute - Return a view of the input with dimensions permuted (swapped) in a certain way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8179f120",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([1., 2., 3., 4., 5., 6., 7., 8., 9.]), torch.Size([9]))"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.arange(1., 10, 1)\n",
    "x, x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f846d27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[5., 2., 3., 4., 5., 6., 7., 8., 9.]]), torch.Size([1, 9]))"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add an extra dimension to the tensor (Must be a multiple of the original tensor's shape)\n",
    "x_reshaped = x.reshape(1, 9) # Reshape the tensor to have 1 row and 9 columns\n",
    "\n",
    "x_reshaped, x_reshaped.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f056640",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1., 2., 3., 4., 5., 6., 7., 8., 9.]]), torch.Size([1, 9]))"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Change the view of the tensor\n",
    "z = x.view(1, 9) # View the tensor as having 9 rows and 1 columns\n",
    "z, z.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab01464a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[5., 2., 3., 4., 5., 6., 7., 8., 9.]]),\n",
       " tensor([5., 2., 3., 4., 5., 6., 7., 8., 9.]))"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Changing z changes x (because they share the same memory)\n",
    "z[:, 0] = 5\n",
    "z, x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d968332",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[5., 2., 3., 4., 5., 6., 7., 8., 9.],\n",
       "         [5., 2., 3., 4., 5., 6., 7., 8., 9.],\n",
       "         [5., 2., 3., 4., 5., 6., 7., 8., 9.],\n",
       "         [5., 2., 3., 4., 5., 6., 7., 8., 9.]]),\n",
       " torch.Size([4, 9]))"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Stack tensors on top of each other\n",
    "x_stacked = torch.stack([x, x, x, x], dim=0) # Stack the tensors on top of each other (dim=0 means stack along the first dimension)\n",
    "x_stacked, x_stacked.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0730e9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original tensor: tensor([[5., 2., 3., 4., 5., 6., 7., 8., 9.]]) \n",
      "Original tensor shape: torch.Size([1, 9])\n",
      "\n",
      "New tensor: tensor([5., 2., 3., 4., 5., 6., 7., 8., 9.]) \n",
      "New tensor shape: torch.Size([9])\n"
     ]
    }
   ],
   "source": [
    "# torch.squeeze() removes all dimensions of size 1 from a tensor\n",
    "#x_reshaped, x_reshaped.shape\n",
    "\n",
    "print(f\"Original tensor: {x_reshaped}\", \n",
    "      f\"\\nOriginal tensor shape: {x_reshaped.shape}\")\n",
    "\n",
    "x_squeezed = torch.squeeze(x_reshaped) # Squeeze the tensor to remove all dimensions of size 1\n",
    "print(f\"\\nNew tensor: {x_squeezed}\", \n",
    "      f\"\\nNew tensor shape: {x_squeezed.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3614893",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous tensor: tensor([5., 2., 3., 4., 5., 6., 7., 8., 9.]) \n",
      "Previous tensor shape: torch.Size([9])\n",
      "\n",
      "New tensor: tensor([[5., 2., 3., 4., 5., 6., 7., 8., 9.]]) \n",
      "New tensor shape: torch.Size([1, 9])\n"
     ]
    }
   ],
   "source": [
    "# torch.unsqueeze() - adds a dimension of size 1 to a tensor at a specified dimension\n",
    "print(f\"Previous tensor: {x_squeezed}\",\n",
    "      f\"\\nPrevious tensor shape: {x_squeezed.shape}\")\n",
    "\n",
    "# Add a dimension of size 1 to the tensor\n",
    "x_unsqueezed = x_squeezed.unsqueeze(dim=0) \n",
    "#x_unsqueezed = torch.unsqueeze(x_squeezed, dim=0)\n",
    "print(f\"\\nNew tensor: {x_unsqueezed}\",\n",
    "      f\"\\nNew tensor shape: {x_unsqueezed.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d5c56ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([5., 2., 3., 4., 5., 6., 7., 8., 9.]), torch.Size([9]))"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Squeeze the tensor to remove all dimensions of size 1\n",
    "x_reshaped.squeeze(), x_reshaped.squeeze().shape # Removes the first dimension of size 1 (First square bracket pair)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "563f5bf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original tensor shape: torch.Size([224, 224, 3]) \n",
      "Permuted tensor shape: torch.Size([3, 224, 224])\n"
     ]
    }
   ],
   "source": [
    "# torch.permute() - rearranges the dimensions of a tensor in a specified order\n",
    "x_original = torch.rand(size=(224, 224, 3)) # [height, width, color channels (R, G, B)]\n",
    "\n",
    "# Permute the original tensor to rearragne the axis (or dimension) order\n",
    "x_permuted = x_original.permute(2, 0, 1) # [color channels (R, G, B), height, width]\n",
    "print(f\"Original tensor shape: {x_original.shape}\",\n",
    "      f\"\\nPermuted tensor shape: {x_permuted.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4479e26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.2266, 0.5740, 0.5148],\n",
       "         [0.4660, 0.7795, 0.7556],\n",
       "         [0.2197, 0.2516, 0.5751],\n",
       "         ...,\n",
       "         [0.9600, 0.6426, 0.5453],\n",
       "         [0.9086, 0.8184, 0.0790],\n",
       "         [0.8952, 0.7947, 0.2273]],\n",
       "\n",
       "        [[0.7873, 0.1554, 0.4412],\n",
       "         [0.5066, 0.3422, 0.7456],\n",
       "         [0.1133, 0.2515, 0.1239],\n",
       "         ...,\n",
       "         [0.2418, 0.2672, 0.8565],\n",
       "         [0.7557, 0.0580, 0.2482],\n",
       "         [0.3169, 0.1066, 0.8245]],\n",
       "\n",
       "        [[0.3290, 0.8507, 0.9695],\n",
       "         [0.2614, 0.9304, 0.1081],\n",
       "         [0.7538, 0.7934, 0.2051],\n",
       "         ...,\n",
       "         [0.8108, 0.9690, 0.1073],\n",
       "         [0.8097, 0.5157, 0.4236],\n",
       "         [0.1917, 0.8679, 0.2034]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.3184, 0.1237, 0.2681],\n",
       "         [0.5060, 0.2082, 0.2176],\n",
       "         [0.1571, 0.5054, 0.9729],\n",
       "         ...,\n",
       "         [0.8451, 0.4620, 0.2496],\n",
       "         [0.7199, 0.4451, 0.8637],\n",
       "         [0.9146, 0.8082, 0.3072]],\n",
       "\n",
       "        [[0.4818, 0.4199, 0.3548],\n",
       "         [0.7362, 0.1898, 0.6271],\n",
       "         [0.6128, 0.0929, 0.2942],\n",
       "         ...,\n",
       "         [0.5380, 0.6917, 0.1384],\n",
       "         [0.0348, 0.1938, 0.3658],\n",
       "         [0.3511, 0.6361, 0.6836]],\n",
       "\n",
       "        [[0.7999, 0.3937, 0.3048],\n",
       "         [0.1176, 0.7584, 0.2508],\n",
       "         [0.3195, 0.4828, 0.3723],\n",
       "         ...,\n",
       "         [0.1768, 0.3839, 0.1556],\n",
       "         [0.8359, 0.8549, 0.8645],\n",
       "         [0.2674, 0.2159, 0.9882]]])"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a40e9a7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R: 0.22657257318496704\n",
      "G: 0.5740078687667847\n",
      "B: 0.5148017406463623\n",
      "?: 0.3422279953956604\n",
      "?: 0.20510190725326538\n",
      "2nd px blue value: 0.44124460220336914\n",
      "2nd px green value: 0.15536683797836304\n",
      "2nd px red value: 0.7872782945632935\n"
     ]
    }
   ],
   "source": [
    "print(f\"R: {x_original[0, 0, 0]}\") # Access the first pixel's red channel value\n",
    "print(f\"G: {x_original[0, 0, 1]}\") # Access the first pixel's green channel value\n",
    "print(f\"B: {x_original[0, 0, 2]}\") # Access the first pixel's blue channel value\n",
    "\n",
    "print(f\"?: {x_original[1, 1, 1]}\") # Access the second pixel's red channel value\n",
    "print(f\"?: {x_original[2, 2, 2]}\") # Access the third pixel's green channel value\n",
    "\n",
    "print(f\"2nd px blue value: {x_original[1, 0, 2]}\") # Access the second pixel's blue channel value\n",
    "print(f\"2nd px green value: {x_original[1, 0, 1]}\") # Access the second pixel's green channel value\n",
    "print(f\"2nd px red value: {x_original[1, 0, 0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8f3e110",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(2266.), tensor(2266.))"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_original[0,0,0] = 2266\n",
    "x_original[0,0,0], x_permuted[0,0,0] # Access the first pixel's red channel value after changing it"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe5530bf",
   "metadata": {},
   "source": [
    "### INDEXING (SELECTING DATA FROM TENSORS)\n",
    "\n",
    "Indexing with PyTorch is similar to indexing with NumPy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c7b2824",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[1, 2, 3],\n",
       "          [4, 5, 6],\n",
       "          [7, 8, 9]]]),\n",
       " torch.Size([1, 3, 3]))"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a tensor\n",
    "\n",
    "x = torch.arange(1, 10, 1).reshape(1, 3, 3)\n",
    "x, x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eadfccd6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1, 2, 3],\n",
       "         [4, 5, 6],\n",
       "         [7, 8, 9]]),\n",
       " torch.Size([3, 3]))"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Index the new tensor\n",
    "x[0], x[0].shape # Access the first element of the tensor (in this case, the first tensor)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c10821a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([1, 2, 3]), torch.Size([3]))"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Index on the middle bracket, or dim=1\n",
    "x[0][0], x[0][0].shape # Access the first element of the first element of the tensor (in this case, the first tensor -> the first row)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fb8aaf0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(1), torch.Size([]))"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Index the most inner bracket, or dim=2 (last bracket/dimension)\n",
    "x[0][0][0], x[0][0][0].shape # Access the first element of the first element of the first element of the tensor (in this case, the first tensor -> the first row -> first element)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67e192a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 3]])"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# You can also use \":\" to select \"all\" of a target dimension\n",
    "x[:,0] # Access all elements of the first dimension (in this case, the first row of the tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45c39dfb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2, 5, 8]])"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get all values of 0th and 1st dimension but only index 1 of the 2nd dimension.\n",
    "x[:, :, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edd12e94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([5])"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get all values of the 0 dimension but only index 1 of the 1st and 2nd dimension.\n",
    "x[:, 1, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd812309",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3])"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get index 0 of the 0th and 1st dimension and all values of the 2nd dimension.\n",
    "x[0, 0, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "786b5739",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(9)"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Index on x to return 9\n",
    "x[0, 2, 2] # 0th dimension, index 2 on row, index 2 on column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38d359ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3, 6, 9])"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Index on x to return 3, 6, 9\n",
    "x[0, :, 2] # 0th dimension, all rows, index 2 on column"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faadebde",
   "metadata": {},
   "source": [
    "### PYTORCH TENSORS & NUMPY\n",
    "\n",
    "NumPy is a popular scientific  Python numerical computing library. Because of this, PyTorch has functionality to interact with it.\n",
    "* Data in NumPy -> PyTorch tensor: `torch.from_numpy(ndarray)`\n",
    "* PyTorch tensor -> data in NumPy: `torch.tensor.numpy()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "072156cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1., 2., 3., 4., 5., 6., 7.]),\n",
       " tensor([1., 2., 3., 4., 5., 6., 7.], dtype=torch.float64))"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# NumPy array to tensor\n",
    "array = np.arange(1.0, 8.0, 1.0)\n",
    "tensor = torch.from_numpy(array) # WARNING: NumPy defaults to float64, PyTorch defaults to float32. Must convert either to match.\n",
    "array, tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82de5643",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([2., 3., 4., 5., 6., 7., 8.]),\n",
       " tensor([1., 2., 3., 4., 5., 6., 7.], dtype=torch.float64))"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Change the value of array, what will this do to `tensor`?\n",
    "array = array + 1\n",
    "array, tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa1a7a1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([1., 1., 1., 1., 1., 1., 1.]),\n",
       " array([1., 1., 1., 1., 1., 1., 1.], dtype=float32))"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tensor to NumPy array\n",
    "tensor = torch.ones(7)\n",
    "numpy_tensor = tensor.numpy()\n",
    "\n",
    "tensor, numpy_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17b338b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([2., 2., 2., 2., 2., 2., 2.]),\n",
       " array([1., 1., 1., 1., 1., 1., 1.], dtype=float32))"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Change the tensor, what will this do to `numpy_tensor`?\n",
    "tensor = tensor + 1\n",
    "tensor, numpy_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4925dd1b",
   "metadata": {},
   "source": [
    "### REPRODUCIBILITY (TAKING THE RANDOM OUT OF RANDOM)\n",
    "\n",
    "In short how neural netwrk learns:\n",
    "`start with random numbers -> tensor operations -> update random numbers to represent data better -> again -> again -> again...` \n",
    "\n",
    "To reduce the randomness in neural networks and PyTorch comes the concept of a **random seed**, which is implimented with `torch.manual_seed()` and is typically active for 1 subsequent line.\n",
    "\n",
    "Essentially, what a random seed does is \"flavor\" the randomness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "69c070e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random tensor A: \n",
      "tensor([[0.4493, 0.6423, 0.4923, 0.7285],\n",
      "        [0.3245, 0.6508, 0.8924, 0.0887],\n",
      "        [0.9698, 0.5627, 0.4893, 0.9633]])\n",
      "\n",
      "Random tensor B: \n",
      "tensor([[0.9475, 0.6314, 0.0067, 0.4262],\n",
      "        [0.9859, 0.3940, 0.4951, 0.5961],\n",
      "        [0.8737, 0.8695, 0.4667, 0.2273]])\n",
      "\n",
      "tensor([[False, False, False, False],\n",
      "        [False, False, False, False],\n",
      "        [False, False, False, False]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Create 2 random tensors\n",
    "random_tensor_A = torch.rand(3, 4)\n",
    "random_tensor_B = torch.rand(3, 4)\n",
    "\n",
    "print(f\"Random tensor A: \\n{random_tensor_A}\\n\")\n",
    "print(f\"Random tensor B: \\n{random_tensor_B}\\n\")\n",
    "\n",
    "print(random_tensor_A == random_tensor_B)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "7d934309",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random tensor C: \n",
      "tensor([[0.4963, 0.7682, 0.0885, 0.1320],\n",
      "        [0.3074, 0.6341, 0.4901, 0.8964],\n",
      "        [0.4556, 0.6323, 0.3489, 0.4017]])\n",
      "\n",
      "Random tensor D: \n",
      "tensor([[0.4963, 0.7682, 0.0885, 0.1320],\n",
      "        [0.3074, 0.6341, 0.4901, 0.8964],\n",
      "        [0.4556, 0.6323, 0.3489, 0.4017]])\n",
      "\n",
      "tensor([[True, True, True, True],\n",
      "        [True, True, True, True],\n",
      "        [True, True, True, True]])\n"
     ]
    }
   ],
   "source": [
    "# Random but reproducible tensors\n",
    "import torch\n",
    "\n",
    "# Set the random seed for reproducibility\n",
    "RANDOM_SEED = 0\n",
    "\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "random_tensor_C = torch.rand(3, 4)\n",
    "\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "random_tensor_D = torch.rand(3, 4)\n",
    "\n",
    "print(f\"Random tensor C: \\n{random_tensor_C}\\n\")\n",
    "print(f\"Random tensor D: \\n{random_tensor_D}\\n\")\n",
    "\n",
    "print(random_tensor_C == random_tensor_D)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e31cbaa8",
   "metadata": {},
   "source": [
    "### RUNNING TENSORS & PYTORCH OBJECTS ON THE GPU (MAKING FASTER COMPUTATIONS)\n",
    "CUDA semantics: https://docs.pytorch.org/docs/stable/notes/cuda.html#cuda-semantics\n",
    "\n",
    "GPUs = faster computation on numbers due to CUDA + NVIDIA Hardware + PyTorch backend.\n",
    "* Best practice to set up device agnostic code, e.g run on GPU if available, else CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "6e488c93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check if GPU is available\n",
    "torch.cuda.is_available()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "54ed6f75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# Setup device-agnostic code\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "e867478c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count the number of devices available\n",
    "torch.cuda.device_count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4044aaa5",
   "metadata": {},
   "source": [
    "### PUTTING TENSORS (OR MODELS) ON THE GPU\n",
    "\n",
    "Because its faster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "3fea2f0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor on device: cpu\n"
     ]
    }
   ],
   "source": [
    "# Create a tensor (defaults to CPU)\n",
    "tensor = torch.tensor([1, 2, 3])\n",
    "\n",
    "#Tensor not on GPU\n",
    "print(f\"Tensor on device: {tensor.device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aef6d57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3], device='cuda:0')"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Move tensor to GPU if available.\n",
    "tensor_on_gpu = tensor.to(device)\n",
    "tensor_on_gpu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "243adff3",
   "metadata": {},
   "source": [
    "### MOVING TENSORS BACK TO CPU\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "f9a3a05a",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "can't convert cuda:0 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[219]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# If tensor is on GPU, cannot transmform into NumPy\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[43mtensor_on_gpu\u001b[49m\u001b[43m.\u001b[49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# Will throw an error if tensor is on GPU\u001b[39;00m\n",
      "\u001b[31mTypeError\u001b[39m: can't convert cuda:0 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first."
     ]
    }
   ],
   "source": [
    "# If tensor is on GPU, cannot transmform into NumPy\n",
    "tensor_on_gpu.numpy() # Will throw an error if tensor is on GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "9afc33b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 3])"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To fix GPU tensor to NumPy, move it back to CPU first\n",
    "tensor_back_on_cpu = tensor_on_gpu.cpu().numpy() # Move tensor back to CPU and convert to NumPy\n",
    "tensor_back_on_cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "47c91044",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3], device='cuda:0')"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_on_gpu"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
