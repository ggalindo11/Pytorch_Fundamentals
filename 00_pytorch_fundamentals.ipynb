{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3f87f393",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello world, lets start playing with pytorch!\n"
     ]
    }
   ],
   "source": [
    "print(\"Hello world, lets start playing with pytorch!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c10e8418",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.7.0+cu128\n",
      "12.8\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(torch.__version__)\n",
    "print(torch.version.cuda)\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad58d879",
   "metadata": {},
   "source": [
    "### INTRODUCTION TO TENSORS\n",
    "Pytorch tensors are creaties using `torch.tensor()` : *https://docs.pytorch.org/docs/stable/generated/torch.tensor.html#torch.tensor*\n",
    "\n",
    "Tensors can be broken down into 4 categories so far:\n",
    "* **scalar(x)** is 0 dimensions, 0 square brackets; a single number; Lower(a)\n",
    "* **vector([x, x])** is 1 dimension, 1 square brackets; a number with direction. i.e wind speed & direction, may have more numbers; Lower(y)\n",
    "* **MATRIX([[x, x], [x, x]])** is 2 dimensions, 2 square brackets; 2 dimensional array of numbers; Upper(Q)\n",
    "*  **TENSOR([x, x, x], [x, x, x], [x, x, x])** is n dimensions, n square brackets; 0 dimensional tensor is scalar, 1 dimension is vector, 2 dimension is matrix; Upper(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9dee9a3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(7)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scalar\n",
    "scalar = torch.tensor(7) # torch.tensor(data, *, dtype=None, device=None, requires_grad=False, pin_memory=False) → Tensorr\n",
    "scalar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3487f4e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scalar.ndim\n",
    "\n",
    "# 0 dimensions because no brackets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "308337dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get tensor back as Python int\n",
    "scalar.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fbea12b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scalar.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0a07d449",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([7, 7])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Vector\n",
    "vector = torch.tensor([7, 7])\n",
    "vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "422f58d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector.ndim\n",
    "\n",
    "# 1 dimension bc 1 bracket pair ...([x, x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4e974c29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "96fd8742",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 7,  8],\n",
       "        [ 9, 10]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MATRIX\n",
    "\n",
    "MATRIX = torch.tensor([[7, 8], \n",
    "                       [9, 10]])\n",
    "\n",
    "MATRIX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "89a2b437",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MATRIX.ndim\n",
    "\n",
    "# 2 dimensions bc 2 bracket pairs, ...([[x, x], [x, x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "405dc21c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([7, 8])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MATRIX[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9cfe1646",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 2])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MATRIX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "70151bab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1, 2, 3, 1, 2],\n",
       "         [3, 6, 9, 2, 3],\n",
       "         [2, 4, 5, 3, 3],\n",
       "         [7, 5, 3, 4, 3]]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TENSOR\n",
    "\n",
    "TENSOR = torch.tensor([[[1, 2 , 3, 1, 2], \n",
    "                        [3, 6, 9, 2, 3], \n",
    "                        [2, 4, 5, 3, 3],\n",
    "                        [7, 5, 3, 4, 3]]])\n",
    "\n",
    "TENSOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "df703c19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TENSOR.ndim\n",
    "\n",
    "# 3 dimensions bc 3 bracket pairs, ...([[[x, x, x], [x, x, x], [x, x, x]]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0ed76e52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 4, 5])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TENSOR.shape\n",
    "\n",
    "#torch.Size([1, 4, 5])\n",
    "# [1, ... Encompases the whole tensor as 1 unit due to all bracket pairs being nested.\n",
    "#  4, ... Encompases the 4 bracket pairs (Can be any amount of bracket paits as long as more than 1)\n",
    "#  5] ... Enxompases the 5 integers in each bracket (can be any amount of integers as long as more than 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59d2afe9",
   "metadata": {},
   "source": [
    "torch.Size([1, y, z])\n",
    "\n",
    "    - [1, ... Encompases the whole tensor as 1 unit due to all bracket pairs being nested.\n",
    "    - y, ... Encompases the y bracket pairs (Can be any amount of bracket paits as long as more than 1)\n",
    "    - z] ... Enxompases the z integers in each bracket (can be any amount of integers as long as more than 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "354c56d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 3, 1, 2],\n",
       "        [3, 6, 9, 2, 3],\n",
       "        [2, 4, 5, 3, 3],\n",
       "        [7, 5, 3, 4, 3]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TENSOR[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f594e3aa",
   "metadata": {},
   "source": [
    "### RANDOM TENSORS\n",
    "\n",
    "Randomized Pytorch tensors are created via `torch.rand()`: *https://docs.pytorch.org/docs/stable/generated/torch.rand.html#torch-rand*\n",
    "\n",
    "Why random tensors?\n",
    "* Random tensors are important bc neural networks learn by starting with tensors of random numbers, then adjusting those random numbers to better represent the data.\n",
    "\n",
    "`Start with random nunbers -> look at daa -> update random numbers -> look at data -> update random numbers`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "766c858f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.3894, 0.6821, 0.5349, 0.1741],\n",
       "        [0.1984, 0.9944, 0.0748, 0.8477],\n",
       "        [0.5217, 0.3853, 0.0297, 0.4463]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a random tensor of size/shape (3, 4)\n",
    "random_TENSOR = torch.rand(3, 4)\n",
    "\n",
    "random_TENSOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9db00e91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([224, 224, 3]), 3)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a random tensor with similar shape to an image tensor\n",
    "random_image_size_TENSOR = torch.rand(size=(224, 224, 3)) # height, width, color channels (R, G, B)\n",
    "\n",
    "random_image_size_TENSOR.shape, random_image_size_TENSOR.ndim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a57c2685",
   "metadata": {},
   "source": [
    "### ZEROS & ONES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ab22ccf3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create tensor of all zeros\n",
    "zeros = torch.zeros(size=(3,4))\n",
    "zeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5153c89d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zeros*random_TENSOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3183ff85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a tensor of all ones\n",
    "ones = torch.ones(size=(3, 4))\n",
    "ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9985e83c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ones.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "aa98dd2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.3894, 0.6821, 0.5349, 0.0000],\n",
       "        [0.1984, 0.9944, 0.0748, 0.0000],\n",
       "        [0.5217, 0.3853, 0.0297, 0.0000]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_with_zero_column = random_TENSOR.clone()\n",
    "tensor_with_zero_column[:, 3] = 0\n",
    "tensor_with_zero_column\n",
    "\n",
    "# makes the last column of the random_TENSOR all zeros"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c499622",
   "metadata": {},
   "source": [
    "### CREATING A RANGE OF TENSORS & TENSORS-LIKE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d18492c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10]),\n",
       " tensor([10,  9,  8,  7,  6,  5,  4,  3,  2,  1,  0]))"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use torch.arange(start, end, step) to create a range of numbers\n",
    "one_to_ten = torch.arange(0, 11, 1)\n",
    "one_to_ten, one_to_ten.flip(0) # reverses range\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "98f4541c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating tensors-like\n",
    "ten_zeros = torch.zeros_like(one_to_ten)\n",
    "ten_zeros"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47258b6b",
   "metadata": {},
   "source": [
    "### TENSOR DATATYPES\n",
    "\n",
    "Tensor datatypes are one of the 3 big errors you'll run into with PyTorch & deep learning:\n",
    "1. Tensors not right datatype\n",
    "2. Tensors not right shape\n",
    "3. Tensors not right device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "378e773a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3.3000, 6.6000, 9.9000])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# FLoat 32 tensor\n",
    "float_32_tensor = torch.tensor([3.3, 6.6, 9.9], \n",
    "                               dtype=None, # what datatype is the tensor; defaults to float32 if not specified (e.g float32 or float16) (float16 is half precision to float32)\n",
    "                                 device=None, # what device the tensor is on; device defaults to CPU if not specified (e.g. 'cpu' or 'cuda:0' for GPU) (e.g. 'cuda:0' for first GPU or 'cuda:1' for second GPU)\n",
    "                                    requires_grad=False) # whether or not to track gradients with this tensors operations; requires_grad defaults to False if not specified\n",
    "\n",
    "float_32_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "bf2b51a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float_32_tensor.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "16284b4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3.3008, 6.6016, 9.8984], dtype=torch.float16)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float_16_tensor = float_32_tensor.type(torch.float16) # convert to float16\n",
    "float_16_tensor\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3f97af6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3.3000, 6.6000, 9.9000], dtype=torch.float64)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float_64_tensor = float_32_tensor.type(torch.float64) # convert to float64\n",
    "float_64_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c1d8459d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([10.8926, 43.5703, 97.9945])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = float_32_tensor * float_16_tensor \n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "32135b6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([10.8900, 43.5600, 98.0100])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float_32_tensor * float_32_tensor # will work because same data type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d1c49d03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([10.8900, 43.5600, 98.0100], dtype=torch.float64)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float_32_tensor * float_64_tensor # will not because same data type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e77f5334",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3, 6, 9], dtype=torch.int32)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int_32_tensor = torch.tensor([3, 6, 9], dtype=torch.int32) # create int32 tensor\n",
    "int_32_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8e3c7004",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 9.9000, 39.6000, 89.1000])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float_32_tensor * int_32_tensor # will work because int32 can be converted to float32"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d762b6ef",
   "metadata": {},
   "source": [
    "### GETTING INFORMATION FROM TENSORS (TENSOR ATTRIBUTES)\n",
    "\n",
    "1. Tensors not right datatype: To get datatype from tensor use, `tensor.dtype`\n",
    "2. Tensors not right shape: To get shape/size from a tensor use, `tensor.shape`\n",
    "3. Tensors not right device: To get device from a tensor use, `tensor.device`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c998a3cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.8450, 0.4236, 0.2306, 0.8298],\n",
       "        [0.3706, 0.9068, 0.2272, 0.1430],\n",
       "        [0.6642, 0.2659, 0.9943, 0.9842]], device='cuda:0')"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a tensor\n",
    "some_TENSOR = torch.rand(size=(3, 4), device=\"cuda:0\") # create a tensor on the first GPU (if available)\n",
    "some_TENSOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "2fe76cc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.8450, 0.4236, 0.2306, 0.8298],\n",
      "        [0.3706, 0.9068, 0.2272, 0.1430],\n",
      "        [0.6642, 0.2659, 0.9943, 0.9842]], device='cuda:0')\n",
      "Datatype of tensor: torch.float32\n",
      "Shape of tensor: torch.Size([3, 4])\n",
      "Device tensor is on: cuda:0\n"
     ]
    }
   ],
   "source": [
    "# Find out the details about some_TENSOR\n",
    "print(some_TENSOR)\n",
    "print(f\"Datatype of tensor: {some_TENSOR.dtype}\")\n",
    "print(f\"Shape of tensor: {some_TENSOR.shape}\")\n",
    "print(f\"Device tensor is on: {some_TENSOR.device}\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdb505c6",
   "metadata": {},
   "source": [
    "### MANIPULATING TENSORS (TENSOR OPERATIONS)\n",
    "\n",
    "Tensor operations include:\n",
    "* Addition\n",
    "* Subtraction\n",
    "* Multiplication (*element-wise*)\n",
    "* Division\n",
    "* Matrix Multiplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "37855828",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([11, 12, 13])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a tensor & add 10 to it\n",
    "TENSOR_1 = torch.tensor([1, 2, 3])\n",
    "TENSOR_1 + 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "1f5ffa68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([10, 20, 30])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Multiplay the tensor by 10\n",
    "TENSOR_1 * 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "1bbacbbf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-9, -8, -7])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Subtract 10 from the tensor\n",
    "TENSOR_1 - 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a3ccc4b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([10, 20, 30])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Try out Pytorch in-built functions\n",
    "torch.mul(TENSOR_1, 10) # multiply by 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "6e5ac21b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([11, 12, 13])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add 10 to the tensor\n",
    "torch.add(TENSOR_1, 10) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23e2c512",
   "metadata": {},
   "source": [
    "### MATRIX MULTIPLICATION\n",
    "\n",
    "*Two main ways to preform multiplication in neural networks & deep learning:*\n",
    "1. Element-Wise multiplication\n",
    "2. Matrix Multiplication (The Dot Product, e.g (a•b))\n",
    "\n",
    "There are 2 main rules to satisfy when preforming Matrix Multiplication\n",
    "1. The **inner dimensions** must match:\n",
    "* `(3,2) @ (3, 2)` won't work\n",
    "* `(2,3) @ (3, 2)` will work\n",
    "* `(3,2) @ (2, 3)` will work\n",
    "\n",
    "2. The resulting Matrix has the shape of the **outer dimensions**:\n",
    "* `(2, 3) @ (3, 2)` -> `(2, 2)`\n",
    "* `(3, 2) @ (2, 3)` -> `(3, 3)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "8a8928e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 2, 3]) * tensor([1, 2, 3])\n",
      "Equals: tensor([1, 4, 9])\n"
     ]
    }
   ],
   "source": [
    "# Element-Wise multiplication\n",
    "print(TENSOR_1, '*', TENSOR_1)\n",
    "print(f\"Equals: {TENSOR_1 * TENSOR_1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "39921599",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(14)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Matrix multiplication\n",
    "torch.matmul(TENSOR_1, TENSOR_1) # tensor([1, 2, 3]) • tensor([1, 2, 3]) dot product\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "897ff28b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Matrix multiplication by hand\n",
    "1*1 + 2*2 + 3*3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "8adc6bfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 0 ns\n",
      "tensor(14)\n"
     ]
    }
   ],
   "source": [
    "# Matrix multiplication by hand with torch\n",
    "# DONT USE THIS, USE torch.matmul() INSTEAD\n",
    "%time\n",
    "value = 0\n",
    "for i in range(len(TENSOR_1)):\n",
    "    value += TENSOR_1[i] * TENSOR_1[i]\n",
    "\n",
    "print(value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "2a8d3946",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 0 ns\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(14)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# USE THIS INSTEAD OF THE ABOVE AND BELOW\n",
    "%time\n",
    "torch.matmul(TENSOR_1, TENSOR_1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "e00a2d55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(14)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Matrix multiplication with @ operator\n",
    "TENSOR_1 @ TENSOR_1 # @ is the same as torch.matmul(), tho less readable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90557598",
   "metadata": {},
   "source": [
    "### COMMON ERROR IN DEEP LEARING: SHAPE ERROR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e03a6ee",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (2x3 and 2x3)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[66]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Shape Error\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmatmul\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrand\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m3\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrand\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m3\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# will throw an error because the shapes don't match for matrix multiplication\u001b[39;00m\n",
      "\u001b[31mRuntimeError\u001b[39m: mat1 and mat2 shapes cannot be multiplied (2x3 and 2x3)"
     ]
    }
   ],
   "source": [
    "# Shape Error\n",
    "torch.matmul(torch.rand(2, 3), torch.rand(2, 3)) # will throw an error because the inne dimensions don't match for matrix multiplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "3aa4c343",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0197, 0.6159, 0.6097],\n",
       "        [0.3468, 0.4634, 0.0968],\n",
       "        [0.5049, 0.4776, 0.2267]])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Will work because the inner dimensions match (3 in this case)\n",
    "torch.matmul(torch.rand(3, 2), torch.rand(2, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "2e924ef1",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (3x2 and 3x2)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[94]\u001b[39m\u001b[32m, line 10\u001b[39m\n\u001b[32m      2\u001b[39m TENSOR_A = torch.tensor([[\u001b[32m1\u001b[39m, \u001b[32m2\u001b[39m],\n\u001b[32m      3\u001b[39m                         [\u001b[32m3\u001b[39m, \u001b[32m4\u001b[39m],\n\u001b[32m      4\u001b[39m                         [\u001b[32m5\u001b[39m, \u001b[32m6\u001b[39m]])\n\u001b[32m      6\u001b[39m TENSOR_B = torch.tensor([[\u001b[32m7\u001b[39m, \u001b[32m8\u001b[39m],\n\u001b[32m      7\u001b[39m                         [\u001b[32m9\u001b[39m, \u001b[32m10\u001b[39m],\n\u001b[32m      8\u001b[39m                         [\u001b[32m11\u001b[39m, \u001b[32m12\u001b[39m]])                 \n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmatmul\u001b[49m\u001b[43m(\u001b[49m\u001b[43mTENSOR_A\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mTENSOR_B\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# will throw an error because the inner dimensions don't match (2 != 3)\u001b[39;00m\n",
      "\u001b[31mRuntimeError\u001b[39m: mat1 and mat2 shapes cannot be multiplied (3x2 and 3x2)"
     ]
    }
   ],
   "source": [
    "# Shape for Matrix multiplication\n",
    "TENSOR_A = torch.tensor([[1, 2],\n",
    "                        [3, 4],\n",
    "                        [5, 6]])\n",
    "\n",
    "TENSOR_B = torch.tensor([[7, 8],\n",
    "                        [9, 10],\n",
    "                        [11, 12]])                 \n",
    "\n",
    "torch.matmul(TENSOR_A, TENSOR_B) # will throw an error because the inner dimensions don't match (2 != 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "55eb766c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([3, 2]), torch.Size([3, 2]))"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TENSOR_A.shape, TENSOR_B.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c503bfe4",
   "metadata": {},
   "source": [
    "To fix a shape issue , we can manipulate the shape of a tensor using a **transpose**.\n",
    "\n",
    "A **transpose** switches the axes or dimensions of a given tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "5663f8eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 7,  8],\n",
       "         [ 9, 10],\n",
       "         [11, 12]]),\n",
       " torch.Size([3, 2]))"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TENSOR_B, TENSOR_B.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5eb611a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 7,  9, 11],\n",
       "         [ 8, 10, 12]]),\n",
       " torch.Size([2, 3]))"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Transpose TENSOR_B to make the inner dimensions match\n",
    "TENSOR_B.T, TENSOR_B.T.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "03a17755",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original shapes: TENSOR_A: torch.Size([3, 2]), TENSOR_B: torch.Size([3, 2]) \n",
      "\n",
      "Transposed shapes: TENSOR_A: torch.Size([3, 2]), TENSOR_B: torch.Size([2, 3]) \n",
      "\n",
      "Multiplying: torch.Size([3, 2]) @ torch.Size([2, 3]) <-- inner dimensions match \n",
      "\n",
      "Result: \n",
      "\n",
      "tensor([[ 23,  29,  35],\n",
      "        [ 53,  67,  81],\n",
      "        [ 83, 105, 127]])\n",
      "\n",
      " Result shape: torch.Size([3, 3]) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# The matrix multiplication operation will now work once Tensor_A or Tensor_B is transposed\n",
    "print(f\"Original shapes: TENSOR_A: {TENSOR_A.shape}, TENSOR_B: {TENSOR_B.shape} \\n\")\n",
    "print(f\"Transposed shapes: TENSOR_A: {TENSOR_A.shape}, TENSOR_B: {TENSOR_B.T.shape} \\n\")\n",
    "print(f\"Multiplying: {TENSOR_A.shape} @ {TENSOR_B.T.shape} <-- inner dimensions match \\n\")\n",
    "\n",
    "result = torch.matmul(TENSOR_A, TENSOR_B.T)\n",
    "print(f\"Result: \\n\")\n",
    "print(result)\n",
    "\n",
    "print(f\"\\n Result shape: {result.shape} \\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
